{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table(\"InsertTableName\",engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'message', 'original', 'genre', 'related', 'request', 'offer',\n",
       "       'aid_related', 'medical_help', 'medical_products', 'search_and_rescue',\n",
       "       'security', 'military', 'child_alone', 'water', 'food', 'shelter',\n",
       "       'clothing', 'money', 'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "related                   20298.0\n",
       "request                    4480.0\n",
       "offer                       119.0\n",
       "aid_related               10878.0\n",
       "medical_help               2087.0\n",
       "medical_products           1314.0\n",
       "search_and_rescue           724.0\n",
       "security                    471.0\n",
       "military                    860.0\n",
       "child_alone                   0.0\n",
       "water                      1674.0\n",
       "food                       2930.0\n",
       "shelter                    2319.0\n",
       "clothing                    406.0\n",
       "money                       604.0\n",
       "missing_people              299.0\n",
       "refugees                    876.0\n",
       "death                      1196.0\n",
       "other_aid                  3448.0\n",
       "infrastructure_related     1705.0\n",
       "transport                  1203.0\n",
       "buildings                  1335.0\n",
       "electricity                 534.0\n",
       "tools                       159.0\n",
       "hospitals                   283.0\n",
       "shops                       120.0\n",
       "aid_centers                 309.0\n",
       "other_infrastructure       1151.0\n",
       "weather_related            7302.0\n",
       "floods                     2158.0\n",
       "storm                      2448.0\n",
       "fire                        282.0\n",
       "earthquake                 2453.0\n",
       "cold                        530.0\n",
       "other_weather              1376.0\n",
       "direct_report              5080.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the count of every category\n",
    "df.iloc[:,4:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the 'child_alone'-category, since it has just zeros and the 'original'-column since we're only interested in the english text\n",
    "df.drop(['child_alone', 'original'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "message                       0\n",
       "original                  16122\n",
       "genre                         0\n",
       "related                     138\n",
       "request                     138\n",
       "offer                       138\n",
       "aid_related                 138\n",
       "medical_help                138\n",
       "medical_products            138\n",
       "search_and_rescue           138\n",
       "security                    138\n",
       "military                    138\n",
       "water                       138\n",
       "food                        138\n",
       "shelter                     138\n",
       "clothing                    138\n",
       "money                       138\n",
       "missing_people              138\n",
       "refugees                    138\n",
       "death                       138\n",
       "other_aid                   138\n",
       "infrastructure_related      138\n",
       "transport                   138\n",
       "buildings                   138\n",
       "electricity                 138\n",
       "tools                       138\n",
       "hospitals                   138\n",
       "shops                       138\n",
       "aid_centers                 138\n",
       "other_infrastructure        138\n",
       "weather_related             138\n",
       "floods                      138\n",
       "storm                       138\n",
       "fire                        138\n",
       "earthquake                  138\n",
       "cold                        138\n",
       "other_weather               138\n",
       "direct_report               138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting for nans\n",
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id message original genre  related  request  offer  aid_related  \\\n",
       "0 NaN     NaN      NaN   NaN      NaN      NaN    NaN          NaN   \n",
       "1 NaN     NaN      NaN   NaN      NaN      NaN    NaN          NaN   \n",
       "2 NaN     NaN      NaN   NaN      NaN      NaN    NaN          NaN   \n",
       "3 NaN     NaN      NaN   NaN      NaN      NaN    NaN          NaN   \n",
       "4 NaN     NaN      NaN   NaN      NaN      NaN    NaN          NaN   \n",
       "\n",
       "   medical_help  medical_products      ...        aid_centers  \\\n",
       "0           NaN               NaN      ...                NaN   \n",
       "1           NaN               NaN      ...                NaN   \n",
       "2           NaN               NaN      ...                NaN   \n",
       "3           NaN               NaN      ...                NaN   \n",
       "4           NaN               NaN      ...                NaN   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                   NaN              NaN     NaN    NaN   NaN         NaN   \n",
       "1                   NaN              NaN     NaN    NaN   NaN         NaN   \n",
       "2                   NaN              NaN     NaN    NaN   NaN         NaN   \n",
       "3                   NaN              NaN     NaN    NaN   NaN         NaN   \n",
       "4                   NaN              NaN     NaN    NaN   NaN         NaN   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0   NaN            NaN            NaN  \n",
       "1   NaN            NaN            NaN  \n",
       "2   NaN            NaN            NaN  \n",
       "3   NaN            NaN            NaN  \n",
       "4   NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because all categorgies have the same number of nans, we should look at some datapoints where nan values exist\n",
    "df[pd.isnull(df)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems that if a category has a nan-value, all of the other columns are nans as well, hence they can be dropped\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = df['message']\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the Grid Search Pipeline-Solution\n",
    "def tokenize(text):\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    clean_tokens = [WordNetLemmatizer().lemmatize(w) for w in tokens if w not in stop_words]\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.36      0.21      0.26       850\n",
      "        1.0       0.66      0.81      0.73      1675\n",
      "        2.0       0.17      0.03      0.05        31\n",
      "\n",
      "avg / total       0.55      0.60      0.57      2556\n",
      "\n",
      "request: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.89      0.76      1680\n",
      "        1.0       0.40      0.14      0.21       876\n",
      "\n",
      "avg / total       0.57      0.63      0.57      2556\n",
      "\n",
      "offer: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2554\n",
      "        1.0       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2556\n",
      "\n",
      "aid_related: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.85      0.73      1569\n",
      "        1.0       0.47      0.21      0.29       987\n",
      "\n",
      "avg / total       0.57      0.60      0.56      2556\n",
      "\n",
      "medical_help: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      2417\n",
      "        1.0       0.00      0.00      0.00       139\n",
      "\n",
      "avg / total       0.89      0.94      0.92      2556\n",
      "\n",
      "medical_products: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      2468\n",
      "        1.0       0.00      0.00      0.00        88\n",
      "\n",
      "avg / total       0.93      0.96      0.95      2556\n",
      "\n",
      "search_and_rescue: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      2496\n",
      "        1.0       0.00      0.00      0.00        60\n",
      "\n",
      "avg / total       0.95      0.98      0.96      2556\n",
      "\n",
      "security: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      2522\n",
      "        1.0       0.00      0.00      0.00        34\n",
      "\n",
      "avg / total       0.97      0.99      0.98      2556\n",
      "\n",
      "military: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2549\n",
      "        1.0       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.99      1.00      1.00      2556\n",
      "\n",
      "water: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      1.00      0.96      2352\n",
      "        1.0       0.00      0.00      0.00       204\n",
      "\n",
      "avg / total       0.85      0.92      0.88      2556\n",
      "\n",
      "food: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.99      0.92      2189\n",
      "        1.0       0.19      0.01      0.03       367\n",
      "\n",
      "avg / total       0.76      0.85      0.79      2556\n",
      "\n",
      "shelter: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.99      0.94      2299\n",
      "        1.0       0.09      0.01      0.01       257\n",
      "\n",
      "avg / total       0.82      0.89      0.85      2556\n",
      "\n",
      "clothing: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      2532\n",
      "        1.0       0.00      0.00      0.00        24\n",
      "\n",
      "avg / total       0.98      0.99      0.99      2556\n",
      "\n",
      "money: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      2518\n",
      "        1.0       0.00      0.00      0.00        38\n",
      "\n",
      "avg / total       0.97      0.99      0.98      2556\n",
      "\n",
      "missing_people: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      2534\n",
      "        1.0       0.00      0.00      0.00        22\n",
      "\n",
      "avg / total       0.98      0.99      0.99      2556\n",
      "\n",
      "refugees: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      2521\n",
      "        1.0       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.97      0.99      0.98      2556\n",
      "\n",
      "death: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      2487\n",
      "        1.0       0.00      0.00      0.00        69\n",
      "\n",
      "avg / total       0.95      0.97      0.96      2556\n",
      "\n",
      "other_aid: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.98      0.92      2197\n",
      "        1.0       0.23      0.04      0.06       359\n",
      "\n",
      "avg / total       0.77      0.85      0.80      2556\n",
      "\n",
      "infrastructure_related: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      2484\n",
      "        1.0       0.00      0.00      0.00        72\n",
      "\n",
      "avg / total       0.94      0.97      0.96      2556\n",
      "\n",
      "transport: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      2503\n",
      "        1.0       0.00      0.00      0.00        53\n",
      "\n",
      "avg / total       0.96      0.98      0.97      2556\n",
      "\n",
      "buildings: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      2462\n",
      "        1.0       0.33      0.01      0.02        94\n",
      "\n",
      "avg / total       0.94      0.96      0.95      2556\n",
      "\n",
      "electricity: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      2536\n",
      "        1.0       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.98      0.99      0.99      2556\n",
      "\n",
      "tools: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2551\n",
      "        1.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2556\n",
      "\n",
      "hospitals: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      2542\n",
      "        1.0       0.00      0.00      0.00        14\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2556\n",
      "\n",
      "shops: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2548\n",
      "        1.0       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.99      1.00      1.00      2556\n",
      "\n",
      "aid_centers: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      2537\n",
      "        1.0       0.00      0.00      0.00        19\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2556\n",
      "\n",
      "other_infrastructure: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      2521\n",
      "        1.0       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.97      0.99      0.98      2556\n",
      "\n",
      "weather_related: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.97      0.91      2166\n",
      "        1.0       0.20      0.04      0.07       390\n",
      "\n",
      "avg / total       0.75      0.83      0.78      2556\n",
      "\n",
      "floods: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      2487\n",
      "        1.0       0.00      0.00      0.00        69\n",
      "\n",
      "avg / total       0.95      0.97      0.96      2556\n",
      "\n",
      "storm: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      2472\n",
      "        1.0       0.38      0.04      0.07        84\n",
      "\n",
      "avg / total       0.95      0.97      0.95      2556\n",
      "\n",
      "fire: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2546\n",
      "        1.0       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.99      1.00      0.99      2556\n",
      "\n",
      "earthquake: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.99      0.95      2338\n",
      "        1.0       0.00      0.00      0.00       218\n",
      "\n",
      "avg / total       0.84      0.91      0.87      2556\n",
      "\n",
      "cold: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      2540\n",
      "        1.0       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2556\n",
      "\n",
      "other_weather: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      2510\n",
      "        1.0       0.00      0.00      0.00        46\n",
      "\n",
      "avg / total       0.96      0.98      0.97      2556\n",
      "\n",
      "direct_report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.90      0.77      1707\n",
      "        1.0       0.39      0.13      0.19       849\n",
      "\n",
      "avg / total       0.58      0.64      0.58      2556\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "for i, col in enumerate(y_test.columns):\n",
    "    print(f\"{col}: \\n\")\n",
    "    print(classification_report(y_test.values[:,i] , y_pred[:,i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] clf__estimator__max_features=auto, clf__estimator__n_estimators=10 \n",
      "[CV]  clf__estimator__max_features=auto, clf__estimator__n_estimators=10, total=  13.9s\n",
      "[CV] clf__estimator__max_features=auto, clf__estimator__n_estimators=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   18.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__max_features=auto, clf__estimator__n_estimators=10, total=  14.0s\n",
      "[CV] clf__estimator__max_features=auto, clf__estimator__n_estimators=10 \n",
      "[CV]  clf__estimator__max_features=auto, clf__estimator__n_estimators=10, total=  14.1s\n",
      "[CV] clf__estimator__max_features=auto, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__max_features=auto, clf__estimator__n_estimators=50, total=  47.5s\n",
      "[CV] clf__estimator__max_features=auto, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__max_features=auto, clf__estimator__n_estimators=50, total=  47.4s\n",
      "[CV] clf__estimator__max_features=auto, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__max_features=auto, clf__estimator__n_estimators=50, total=  48.5s\n",
      "[CV] clf__estimator__max_features=log2, clf__estimator__n_estimators=10 \n",
      "[CV]  clf__estimator__max_features=log2, clf__estimator__n_estimators=10, total=  14.3s\n",
      "[CV] clf__estimator__max_features=log2, clf__estimator__n_estimators=10 \n",
      "[CV]  clf__estimator__max_features=log2, clf__estimator__n_estimators=10, total=  14.4s\n",
      "[CV] clf__estimator__max_features=log2, clf__estimator__n_estimators=10 \n",
      "[CV]  clf__estimator__max_features=log2, clf__estimator__n_estimators=10, total=  14.7s\n",
      "[CV] clf__estimator__max_features=log2, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__max_features=log2, clf__estimator__n_estimators=50, total=  49.7s\n",
      "[CV] clf__estimator__max_features=log2, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__max_features=log2, clf__estimator__n_estimators=50, total=  50.3s\n",
      "[CV] clf__estimator__max_features=log2, clf__estimator__n_estimators=50 \n",
      "[CV]  clf__estimator__max_features=log2, clf__estimator__n_estimators=50, total=  50.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__estimator__max_features': ['auto', 'log2'], 'clf__estimator__n_estimators': [10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'clf__estimator__max_features': [\"auto\", \"log2\"],\n",
    "              'clf__estimator__n_estimators': [10, 50]}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, verbose=2, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = classification_report(y_test.values[:,i] , y_pred[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Precision: 0.5\n",
      "Recall: 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#y_pred = cv.predict(X_test)\n",
    "acc = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for i, col in enumerate(y_test.columns):\n",
    "    acc.append(accuracy_score(y_test.values[i,:], y_pred[i,:]))\n",
    "    precision.append(precision_score(y_test.values[i,:], y_pred[i,:]))\n",
    "    recall.append(recall_score(y_test.values[i,:], y_pred[i,:]))\n",
    "\n",
    "print(f\"Accuracy: {np.mean(acc):.2}\")\n",
    "print(f\"Precision: {np.mean(precision):.2}\")\n",
    "print(f\"Recall: {np.mean(recall):.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
